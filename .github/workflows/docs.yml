name: Docs

on:
  push:
    branches: [ "main" ]
    paths:
      - "docs/**"
      - "mkdocs.yml"
      - "requirements.txt"
  workflow_dispatch:
  workflow_run:
    workflows:
      - "CaribData Open Data — Build & Release"
      - "CaribData Messy Data — Fetch & Bundle"
      - "CaribData Messy Data — Release"
    types: [completed]

permissions:
  contents: write
  actions: read

concurrency:
  group: docs-site
  cancel-in-progress: true

jobs:
  build-deploy:
    if: github.event_name != 'workflow_run' || (github.event.workflow_run.conclusion == 'success')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install MkDocs (minimal)
        run: |
          set -eux
          pip install mkdocs mkdocs-material
          mkdocs --version

      - name: Checkout gh-pages (read-only)
        uses: actions/checkout@v4
        continue-on-error: true
        with:
          ref: gh-pages
          path: ghp
          fetch-depth: 0

      - name: Inspect gh-pages (debug)
        run: |
          set -eux
          ls -la ghp || true
          ls -la ghp/data || true
          [ -f ghp/data/latest.json ] && { echo "latest.json:"; cat ghp/data/latest.json; } || echo "(no latest.json)"
          echo "Tag dirs under ghp/data:"
          find ghp/data -mindepth 1 -maxdepth 1 -type d -printf "%f\n" 2>/dev/null | sort -V || true
          echo "Messy tags:"
          [ -d ghp/data/messy ] && ls -1 ghp/data/messy | sort -V || echo "(no messy/)"

      - name: Generate Downloads page
        run: |
          set -euo pipefail
          mkdir -p docs
          OWNER="${GITHUB_REPOSITORY_OWNER}"
          REPO="${GITHUB_REPOSITORY#*/}"
          BASE_URL="https://${OWNER}.github.io/${REPO}"
          urlencode_path () { local in="$1"; in="${in// /%20}"; in="${in//(/%28}"; in="${in//)/%29}"; in="${in//&/%26}"; in="${in//#/%23}"; echo "$in"; }

          LATEST_TAG=""
          if [ -f ghp/data/latest.json ]; then
            LATEST_TAG="$(grep -oE '"tag"\s*:\s*"[^"]+"' ghp/data/latest.json | sed -E 's/.*"tag"\s*:\s*"([^"]+)".*/\1/' || true)"
          fi
          if [ -z "$LATEST_TAG" ]; then
            LATEST_TAG="$(find ghp/data -mindepth 1 -maxdepth 1 -type d -printf "%f\n" 2>/dev/null | grep -E '^(v|od-)' | sort -V | tail -n 1 || true)"
          fi

          MESSY_TAG=""
          if [ -d ghp/data/messy ]; then
            MESSY_TAG="$(ls -1 ghp/data/messy | sort -V | tail -n 1 || true)"
          fi

          {
            echo "# Downloads"
            echo
            if [ -n "$LATEST_TAG" ] && [ -d "ghp/data/$LATEST_TAG" ]; then
              echo "## Open Data — Latest: \`$LATEST_TAG\`"
              echo
              for p in "_freshness.json" "_quality_report.csv" "_quality_report.json" "world_bank/_dictionary.csv" "world_bank/_manifest.json" "faostat_fbs/_manifest.json"; do
                [ -f "ghp/data/$LATEST_TAG/$p" ] && rel="data/$LATEST_TAG/$p" && echo "- [$p](${BASE_URL}/$(urlencode_path "$rel"))"
              done
              echo
              if [ -d "ghp/data/$LATEST_TAG/world_bank" ]; then
                echo "### World Bank CSVs"
                for country in $(find "ghp/data/$LATEST_TAG/world_bank" -mindepth 1 -maxdepth 1 -type d -printf "%f\n" | sort); do
                  echo "- **$country**"
                  for f in $(find "ghp/data/$LATEST_TAG/world_bank/$country" -type f -name "*.csv" | sort); do
                    bn="$(basename "$f")"; rel="${f#ghp/}"
                    echo "  - [$bn](${BASE_URL}/$(urlencode_path "$rel"))"
                  done
                done
                echo
              fi
              if [ -d "ghp/data/$LATEST_TAG/faostat_fbs" ]; then
                echo "### FAOSTAT FBS CSVs"
                for f in $(find "ghp/data/$LATEST_TAG/faostat_fbs" -type f -name "*_fbs.csv" | sort); do
                  bn="$(basename "$f")"; rel="${f#ghp/}"
                  echo "- [$bn](${BASE_URL}/$(urlencode_path "$rel"))"
                done
                echo
              fi
            else
              echo "## Open Data — (no published tag found yet)"
              echo
            fi

            echo "## Messy Data (Belize)"
            if [ -n "$MESSY_TAG" ] && [ -d "ghp/data/messy/$MESSY_TAG" ]; then
              echo "_Latest messy tag:_ \`$MESSY_TAG\`"
              echo
              for p in "_manifest.json" "_report.json" "_dataset_card.md"; do
                [ -f "ghp/data/messy/$MESSY_TAG/$p" ] && rel="data/messy/$MESSY_TAG/$p" && echo "- [$p](${BASE_URL}/$(urlencode_path "$rel"))"
              done
              echo
              echo "### Raw files"
              if [ -d "ghp/data/messy/$MESSY_TAG/raw" ]; then
                for slug in $(find "ghp/data/messy/$MESSY_TAG/raw" -mindepth 1 -maxdepth 1 -type d -printf "%f\n" | sort); do
                  echo "- **$slug**"
                  for f in $(find "ghp/data/messy/$MESSY_TAG/raw/$slug" -type f \( -iname "*.xlsx" -o -iname "*.xls" -o -iname "*.csv" \) | sort); do
                    bn="$(basename "$f")"; rel="${f#ghp/}"
                    echo "  - [$bn](${BASE_URL}/$(urlencode_path "$rel"))"
                  done
                done
                echo
              fi
            else
              echo "_No messy data published yet._"
              echo
            fi

            echo "## All Open Data tags"
            TAGS="$(find ghp/data -mindepth 1 -maxdepth 1 -type d -printf "%f\n" 2>/dev/null | grep -E '^(v|od-)' | sort -V || true)"
            if [ -n "$TAGS" ]; then
              while IFS= read -r t; do
                [ -z "$t" ] && continue
                echo "- [$t](${BASE_URL}/data/${t}/)"
              done <<< "$TAGS"
              echo
            fi
          } > docs/downloads.md

          echo "DEBUG: first lines of generated docs/downloads.md"
          head -n 120 docs/downloads.md || true

      - name: Build site
        run: |
          set -eux
          mkdocs build --strict

      - name: Deploy to GitHub Pages (preserve existing data/)
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./site
          publish_branch: gh-pages
          keep_files: true
          force_orphan: false
